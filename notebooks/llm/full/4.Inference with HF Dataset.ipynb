{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18292183-dcbd-4197-9162-ff9024e4955a",
   "metadata": {},
   "source": [
    "# Inference With HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7495d7-38ea-4cac-844d-da511af5e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from bigdl.llm.transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78c0c9-e2e8-4582-943e-f26b56584669",
   "metadata": {},
   "source": [
    "## Inference with newly Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ddbe3-32ef-423a-97b8-4966aa6fd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"outputs/merged-llm\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                                 load_in_4bit=True,\n",
    "                                                 optimize_model=True,\n",
    "                                                 trust_remote_code=True,\n",
    "                                                 use_cache=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = model.to('xpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531783ce-a827-4da9-ac49-0ac7160c0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PROMPT = \"{prompt}\"\n",
    "with torch.inference_mode():\n",
    "    prompt = MODEL_PROMPT.format(prompt=\"Two things are infinite\")\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to('xpu')\n",
    "    output = model.generate(input_ids, max_new_tokens=20)\n",
    "    torch.xpu.synchronize()\n",
    "    output = output.cpu()\n",
    "    output_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e5e72",
   "metadata": {},
   "source": [
    "## Notices & Disclaimers \n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation. \n",
    "\n",
    "No product or component can be absolutely secure.  \n",
    "\n",
    "Your costs and results may vary.  \n",
    "\n",
    "No license (express or implied, by estoppel or otherwise) to any intellectual property rights is granted by this document, with the sole exception that code included in this document is licensed subject to the Zero-Clause BSD open source license (0BSD), Open Source Initiative. No rights are granted to create modifications or derivatives of this document. \n",
    "\n",
    "© Intel Corporation.  Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries.  Other names and brands may be claimed as the property of others.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
